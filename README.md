# music-generating-program
A Music Generating Program Depending on Difference In Two Subsequent Frames In A Video Using Image Processing Techniques
In this, we tried to create a program that creates music based on the movements in the video using Python. We got the inspiration for this idea from the “Iamascope: A Musical Application for Image Processing” report. We use image processing techniques like canny edge detection, image thresholding, image resizing, etc. to detect the movement of the object (or a person) in the video provided as an input and play different musical tones (musical notes or octave) depending on the movement happening in the video at an interval of 15 frames or 0.5 sec as it works on 30fps video for now. The main objective of this project is to create a program which can be used to generate background sound for the muted videos or can be used in real-time (after making required changes) on the basis of changes or movement occured in them at an interval of 0.5 sec. The interval in terms of frames is set to 15 frames for now as we have used 30 fps video as an input and could be set according to the need of the user. The sample rate for the sound is set to 44100 Hz to get a near 320 kbps sound quality.
